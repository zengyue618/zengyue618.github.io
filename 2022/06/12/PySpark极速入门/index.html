
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>PySpark极速入门 - Hexo</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="TriDiamond Obsidian,"> 
    <meta name="description" content="PySpark极速入门一：Pyspark简介与安装什么是Pyspark？PySpark是Spark的Python语言接口，通过它，可以使用Python API编写Spark应用程序，目前支持绝大多数,"> 
    <meta name="author" content="Zeng Yue"> 
    <link rel="alternative" href="atom.xml" title="Hexo" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
<link rel="stylesheet" href="//at.alicdn.com/t/font_1429596_nzgqgvnmkjb.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.7.2/animate.min.css">

    
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/codemirror.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/theme/dracula.css">

    
<link rel="stylesheet" href="/css/obsidian.css">

    
<link rel="stylesheet" href="/css/ball-atom.min.css">

    
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">

    
    <script>var musiclist = "7471325035"</script>
    
<script src="/js/loadaplayer.js"></script>

    <!-- 引用依赖 -->
    
<link rel="stylesheet" href="/aplayer/dist/APlayer.min.css">

    
<script src="/aplayer/dist/APlayer.min.js"></script>
<script src="/js/Meting.min.js"></script>

    
<meta name="generator" content="Hexo 6.2.0"></head>


<body class="loading">
    <div class="loader">
        <div class="la-ball-atom la-2x">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
    <span id="config-title" style="display:none">Hexo</span>
    <div id="loader"></div>
    <div id="single">
    <div class="scrollbar gradient-bg-rev"></div>
<div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <div class="navigation animated fadeIn fast delay-1s">
        <img id="home-icon" class="icon-home" src="/img/favicon.png" alt="" data-url="http://example.com">
        <div id="play-icon" title="Play/Pause" class="iconfont icon-play"></div>
        <h3 class="subtitle">PySpark极速入门</h3>
        <div class="social">
            <!--        <div class="like-icon">-->
            <!--            <a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
            <!--        </div>-->
            <div>
                <div class="share">
                    
                        <a href="javascript:;" class="iconfont icon-share1"></a>
                        <div class="share-component-cc" data-disabled="facebook,douban,linkedin,diandian,tencent,google"></div>
                    
                </div>
            </div>
        </div>
    </div>
</div>

    <div class="section">
        <div class=article-header-wrapper>
    <div class="article-header">
        <div class="article-cover animated fadeIn" style="
            animation-delay: 600ms;
            animation-duration: 1.2s;
            background-image: 
                radial-gradient(ellipse closest-side, rgba(0, 0, 0, 0.65), #100e17),
                url('https://s1.328888.xyz/2022/06/04/WIr9R.jpg') ">
        </div>
        <div class="else">
            <p class="animated fadeInDown">
                
                <a href="/categories/大数据技术"><b>「
                    </b>大数据技术<b> 」</b></a>
                
                June 12, 2022
            </p>
            <h3 class="post-title animated fadeInDown"><a href="/2022/06/12/PySpark%E6%9E%81%E9%80%9F%E5%85%A5%E9%97%A8/" title="PySpark极速入门" class="">PySpark极速入门</a>
            </h3>
            
            <p class="post-count animated fadeInDown">
                
                <span>
                    <b class="iconfont icon-text2"></b> <i>Words count</i>
                    17k
                </span>
                
                
                <span>
                    <b class="iconfont icon-timer__s"></b> <i>Reading time</i>
                    15 mins.
                </span>
                
                
                
                <span id="busuanzi_container_page_pv">
                    <b class="iconfont icon-read"></b> <i>Read count</i>
                    <span id="busuanzi_value_page_pv">0</span>
                </span>
                
            </p>
            
            
            <ul class="animated fadeInDown post-tags-list" itemprop="keywords"><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Spark/" rel="tag">Spark</a></li></ul>
            
        </div>
    </div>
</div>

<div class="screen-gradient-after">
    <div class="screen-gradient-content">
        <div class="screen-gradient-content-inside">
            <div class="bold-underline-links screen-gradient-sponsor">
                <p>
                    <span class="animated fadeIn delay-1s"></span>
                </p>
            </div>
        </div>
    </div>
</div>

<div class="article">
    <div class='main'>
        <div class="content markdown animated fadeIn">
            <h1 id="PySpark极速入门"><a href="#PySpark极速入门" class="headerlink" title="PySpark极速入门"></a>PySpark极速入门</h1><h2 id="一：Pyspark简介与安装"><a href="#一：Pyspark简介与安装" class="headerlink" title="一：Pyspark简介与安装"></a>一：Pyspark简介与安装</h2><h4 id="什么是Pyspark？"><a href="#什么是Pyspark？" class="headerlink" title="什么是Pyspark？"></a>什么是Pyspark？</h4><p>PySpark是Spark的Python语言接口，通过它，可以使用Python API编写Spark应用程序，目前支持绝大多数Spark功能。目前Spark官方在其支持的所有语言中，将Python置于首位。</p>
<p><img src="https://s1.328888.xyz/2022/06/12/Co98B.png" alt="Co98B.png"></p>
<h4 id="如何安装？"><a href="#如何安装？" class="headerlink" title="如何安装？"></a>如何安装？</h4><p>在终端输入</p>
<pre><code class="shell">pip intsall pyspark
</code></pre>
<p><img src="https://s1.328888.xyz/2022/06/12/CvNZA.png" alt="CvNZA.png"></p>
<p>或者使用pycharm，在GUI界面安装</p>
<p><img src="https://s1.328888.xyz/2022/06/12/CvMsm.png" alt="CvMsm.png"></p>
<h2 id="二：编程实践"><a href="#二：编程实践" class="headerlink" title="二：编程实践"></a>二：编程实践</h2><h3 id="加载、转换数据"><a href="#加载、转换数据" class="headerlink" title="加载、转换数据"></a>加载、转换数据</h3><pre><code class="python"># 导入pyspark
# 导入pandas, 稍后与pyspark中的数据结构做对比
import pyspark
import pandas as pd
</code></pre>
<p>在编写spark程序前，我们要创建一个SparkSession对象</p>
<pre><code class="python">from pyspark.sql import SparkSession
spark = SparkSession.builder.appName(&quot;Spark极速入门&quot;).getOrCreate()
</code></pre>
<p>可以看到会话的一些信息：使用的Spark版本、运行模式、应用程序名字</p>
<p>演示环境用的是local本地模式， * 代表的是使用全部线程<br>如果想用集群模式的话，可以去查看集群搭建的相关教程<br>届时pyspark程序作为spark的客户端，设置连接集群，就是真正的分布式计算了<br>目前只是本地模式，用多线程去模拟分布式计算。</p>
<pre><code class="python">spark
</code></pre>
<p><img src="https://s1.328888.xyz/2022/06/12/CoGE4.png" alt="CoGE4.png"></p>
<p>看看我们将用到的test1数据吧</p>
<p><img src="https://s1.328888.xyz/2022/06/12/CNziq.png" alt="CNziq.png"></p>
<p>使用read方法，用option设置是否读取csv的头，再指定路径就可以读取数据了</p>
<pre><code class="python">df_spark = spark.read.option(&quot;header&quot;, &quot;true&quot;).csv(&quot;./data/test1.csv&quot;)
</code></pre>
<p>看看是什么类型</p>
<pre><code class="python">type(df_spark)
</code></pre>
<pre><code>pyspark.sql.dataframe.DataFrame
</code></pre>
<p>再看看用pandas读取是什么类型</p>
<pre><code class="python">type(pd.read_csv(&quot;./data/test1.csv&quot;))
</code></pre>
<pre><code>pandas.core.frame.DataFrame
</code></pre>
<p>可以发现Spark读取这种结构化数据时，用的也是和pandas类似的dataframe结构<br>这也是Spark应用最广泛的数据结构</p>
<p>使用show方法打印数据</p>
<pre><code class="python">df_spark.show()
</code></pre>
<pre><code>+---------+---+----------+------+
|     Name|age|Experience|Salary|
+---------+---+----------+------+
|    Krish| 31|        10| 30000|
|Sudhanshu| 30|         8| 25000|
|    Sunny| 29|         4| 20000|
|     Paul| 24|         3| 20000|
|   Harsha| 21|         1| 15000|
|  Shubham| 23|         2| 18000|
+---------+---+----------+------+
</code></pre>
<p>​    </p>
<p>使用printSchema方法打印元数据信息，发现明明是数值类型的，它却读取为了字符串类型</p>
<pre><code class="python">df_spark.printSchema()
</code></pre>
<pre><code>root
 |-- Name: string (nullable = true)
 |-- age: string (nullable = true)
 |-- Experience: string (nullable = true)
 |-- Salary: string (nullable = true)
</code></pre>
<p>​    </p>
<p>在读取时，加上类型推断,发现此时已经能正确读取了</p>
<pre><code class="python">df_spark = spark.read.option(&quot;header&quot;, &quot;true&quot;).csv(&quot;./data/test1.csv&quot;,inferSchema=True)
df_spark.printSchema()
</code></pre>
<pre><code>root
 |-- Name: string (nullable = true)
 |-- age: integer (nullable = true)
 |-- Experience: integer (nullable = true)
 |-- Salary: integer (nullable = true)
</code></pre>
<p>​    </p>
<p>选择某些列, 可以发现不管选多列还是选单列，返回的都是dataframe<br>返回的也同样可以printSchema、show等dataframe使用的方法，做到了结构的统一</p>
<pre><code class="python">df_spark.select([&quot;Name&quot;, &quot;age&quot;])
</code></pre>
<pre><code>DataFrame[Name: string, age: int]
</code></pre>
<pre><code class="python">df_spark.select(&quot;Name&quot;)
</code></pre>
<pre><code>DataFrame[Name: string]
</code></pre>
<pre><code class="python">df_spark.select([&quot;Name&quot;, &quot;age&quot;, &quot;Salary&quot;]).printSchema()
</code></pre>
<pre><code>root
 |-- Name: string (nullable = true)
 |-- age: integer (nullable = true)
 |-- Salary: integer (nullable = true)
</code></pre>
<p>​    </p>
<p>不用select，而用[]直接选取，就有点类似与pandas的series了</p>
<pre><code class="python">df_spark[&quot;Name&quot;]
</code></pre>
<pre><code>Column&lt;&#39;Name&#39;&gt;
</code></pre>
<p>column就不能直接show了</p>
<pre><code class="python">df_spark[&quot;age&quot;].show()
</code></pre>
<pre><code>---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

Input In [15], in &lt;cell line: 1&gt;()
----&gt; 1 df_spark[&quot;age&quot;].show()


TypeError: &#39;Column&#39; object is not callable
</code></pre>
<p>用describe方法可以对dataframe做一些简单的统计</p>
<pre><code class="python">df_spark.describe().show()
</code></pre>
<pre><code>+-------+------+------------------+-----------------+------------------+
|summary|  Name|               age|       Experience|            Salary|
+-------+------+------------------+-----------------+------------------+
|  count|     6|                 6|                6|                 6|
|   mean|  null|26.333333333333332|4.666666666666667|21333.333333333332|
| stddev|  null| 4.179314138308661|3.559026084010437| 5354.126134736337|
|    min|Harsha|                21|                1|             15000|
|    max| Sunny|                31|               10|             30000|
+-------+------+------------------+-----------------+------------------+
</code></pre>
<p>​    </p>
<p>用withColumn方法给dataframe加上一列</p>
<pre><code class="python">df_spark = df_spark.withColumn(&quot;Experience After 3 year&quot;, df_spark[&quot;Experience&quot;] + 3)
</code></pre>
<pre><code class="python">df_spark.show()
</code></pre>
<pre><code>+---------+---+----------+------+-----------------------+
|     Name|age|Experience|Salary|Experience After 3 year|
+---------+---+----------+------+-----------------------+
|    Krish| 31|        10| 30000|                     13|
|Sudhanshu| 30|         8| 25000|                     11|
|    Sunny| 29|         4| 20000|                      7|
|     Paul| 24|         3| 20000|                      6|
|   Harsha| 21|         1| 15000|                      4|
|  Shubham| 23|         2| 18000|                      5|
+---------+---+----------+------+-----------------------+
</code></pre>
<p>​    </p>
<p>用drop方法删除列</p>
<pre><code class="python">df_spark = df_spark.drop(&quot;Experience After 3 year&quot;)
df_spark.show()
</code></pre>
<pre><code>+---------+---+----------+------+
|     Name|age|Experience|Salary|
+---------+---+----------+------+
|    Krish| 31|        10| 30000|
|Sudhanshu| 30|         8| 25000|
|    Sunny| 29|         4| 20000|
|     Paul| 24|         3| 20000|
|   Harsha| 21|         1| 15000|
|  Shubham| 23|         2| 18000|
+---------+---+----------+------+
</code></pre>
<p>​    </p>
<p>用withColumnRename方法重命名列</p>
<pre><code class="python">df_spark.withColumnRenamed(&quot;Name&quot;, &quot;New Name&quot;).show()
</code></pre>
<pre><code>+---------+---+----------+------+
| New Name|age|Experience|Salary|
+---------+---+----------+------+
|    Krish| 31|        10| 30000|
|Sudhanshu| 30|         8| 25000|
|    Sunny| 29|         4| 20000|
|     Paul| 24|         3| 20000|
|   Harsha| 21|         1| 15000|
|  Shubham| 23|         2| 18000|
+---------+---+----------+------+
</code></pre>
<p>​    </p>
<h3 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h3><p>看看接下来要带缺失值的test2数据吧</p>
<p><img src="https://s1.328888.xyz/2022/06/12/CSeoe.png" alt="CSeoe.png"></p>
<pre><code class="python">df_spark = spark.read.csv(&quot;./data/test2.csv&quot;, header=True, inferSchema=True)
df_spark.show()
</code></pre>
<pre><code>+---------+----+----------+------+
|     Name| age|Experience|Salary|
+---------+----+----------+------+
|    Krish|  31|        10| 30000|
|Sudhanshu|  30|         8| 25000|
|    Sunny|  29|         4| 20000|
|     Paul|  24|         3| 20000|
|   Harsha|  21|         1| 15000|
|  Shubham|  23|         2| 18000|
|   Mahesh|null|      null| 40000|
|     null|  34|        10| 38000|
|     null|  36|      null|  null|
+---------+----+----------+------+
</code></pre>
<p>​    </p>
<p>用na.drop删除缺失值<br>how参数设置策略，any意思是只要一行里有缺失值，那就删了<br>any也是how的默认参数</p>
<pre><code class="python">df_spark.na.drop(how=&quot;any&quot;).show()
</code></pre>
<pre><code>+---------+---+----------+------+
|     Name|age|Experience|Salary|
+---------+---+----------+------+
|    Krish| 31|        10| 30000|
|Sudhanshu| 30|         8| 25000|
|    Sunny| 29|         4| 20000|
|     Paul| 24|         3| 20000|
|   Harsha| 21|         1| 15000|
|  Shubham| 23|         2| 18000|
+---------+---+----------+------+
</code></pre>
<p>​    </p>
<p>可以通过thresh参数设置阈值，代表超过一行中缺失值的数量超过这个值，才会被删除</p>
<pre><code class="python">df_spark.na.drop(how=&quot;any&quot;, thresh=2).show()
</code></pre>
<pre><code>+---------+----+----------+------+
|     Name| age|Experience|Salary|
+---------+----+----------+------+
|    Krish|  31|        10| 30000|
|Sudhanshu|  30|         8| 25000|
|    Sunny|  29|         4| 20000|
|     Paul|  24|         3| 20000|
|   Harsha|  21|         1| 15000|
|  Shubham|  23|         2| 18000|
|   Mahesh|null|      null| 40000|
|     null|  34|        10| 38000|
+---------+----+----------+------+
</code></pre>
<p>​    </p>
<p>也可以用subset参数设置关注的列<br>下面代码意思是，在Experience列中，只要有缺失值就删掉</p>
<pre><code class="python">df_spark.na.drop(how=&quot;any&quot;, subset=[&quot;Experience&quot;]).show()
</code></pre>
<pre><code>+---------+---+----------+------+
|     Name|age|Experience|Salary|
+---------+---+----------+------+
|    Krish| 31|        10| 30000|
|Sudhanshu| 30|         8| 25000|
|    Sunny| 29|         4| 20000|
|     Paul| 24|         3| 20000|
|   Harsha| 21|         1| 15000|
|  Shubham| 23|         2| 18000|
|     null| 34|        10| 38000|
+---------+---+----------+------+
</code></pre>
<p>​    </p>
<p>用fillna填充缺失值, 可以用字典对各列的填充值进行设置</p>
<pre><code class="python">df_spark.fillna(&#123;&#39;Name&#39;: &#39;unknown&#39;, &#39;age&#39;: 18, &#39;Experience&#39;: 0, &#39;Salary&#39;: 0&#125;).show()
</code></pre>
<pre><code>+---------+---+----------+------+
|     Name|age|Experience|Salary|
+---------+---+----------+------+
|    Krish| 31|        10| 30000|
|Sudhanshu| 30|         8| 25000|
|    Sunny| 29|         4| 20000|
|     Paul| 24|         3| 20000|
|   Harsha| 21|         1| 15000|
|  Shubham| 23|         2| 18000|
|   Mahesh| 18|         0| 40000|
|  unknown| 34|        10| 38000|
|  unknown| 36|         0|     0|
+---------+---+----------+------+
</code></pre>
<p>​    </p>
<p>还可以调用机器学习模块的相关方法，<br>通过设置策略，可以用平均数、众数等方式填充</p>
<pre><code class="python">from pyspark.ml.feature import Imputer

imputer = Imputer(
    inputCols = [&#39;age&#39;, &#39;Experience&#39;, &#39;Salary&#39;],
    outputCols = [f&quot;&#123;c&#125;_imputed&quot; for c in [&#39;age&#39;, &#39;Experience&#39;, &#39;Salary&#39;]]
).setStrategy(&quot;mean&quot;)
</code></pre>
<pre><code class="python">imputer.fit(df_spark).transform(df_spark).show()
</code></pre>
<pre><code>+---------+----+----------+------+-----------+------------------+--------------+
|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|
+---------+----+----------+------+-----------+------------------+--------------+
|    Krish|  31|        10| 30000|         31|                10|         30000|
|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|
|    Sunny|  29|         4| 20000|         29|                 4|         20000|
|     Paul|  24|         3| 20000|         24|                 3|         20000|
|   Harsha|  21|         1| 15000|         21|                 1|         15000|
|  Shubham|  23|         2| 18000|         23|                 2|         18000|
|   Mahesh|null|      null| 40000|         28|                 5|         40000|
|     null|  34|        10| 38000|         34|                10|         38000|
|     null|  36|      null|  null|         36|                 5|         25750|
+---------+----+----------+------+-----------+------------------+--------------+
</code></pre>
<p>​    </p>
<h3 id="过滤操作"><a href="#过滤操作" class="headerlink" title="过滤操作"></a>过滤操作</h3><p>还是切换到test1数据</p>
<pre><code class="python">df_spark = spark.read.csv(&quot;./data/test1.csv&quot;, header=True, inferSchema=True)
df_spark.show()
</code></pre>
<pre><code>+---------+---+----------+------+
|     Name|age|Experience|Salary|
+---------+---+----------+------+
|    Krish| 31|        10| 30000|
|Sudhanshu| 30|         8| 25000|
|    Sunny| 29|         4| 20000|
|     Paul| 24|         3| 20000|
|   Harsha| 21|         1| 15000|
|  Shubham| 23|         2| 18000|
+---------+---+----------+------+
</code></pre>
<p>​    </p>
<p>可以使用filter方法对数据进行过滤操作，类似于SQL中的where<br>可以使用字符串的方式，也可以利用column方式去传递条件</p>
<pre><code class="python">df_spark.filter(&quot;Salary &lt;= 20000&quot;).show()
</code></pre>
<pre><code>+-------+---+----------+------+
|   Name|age|Experience|Salary|
+-------+---+----------+------+
|  Sunny| 29|         4| 20000|
|   Paul| 24|         3| 20000|
| Harsha| 21|         1| 15000|
|Shubham| 23|         2| 18000|
+-------+---+----------+------+
</code></pre>
<p>​    </p>
<pre><code class="python">df_spark.filter(df_spark[&quot;Salary&quot;]&lt;=20000).show()
</code></pre>
<pre><code>+-------+---+----------+------+
|   Name|age|Experience|Salary|
+-------+---+----------+------+
|  Sunny| 29|         4| 20000|
|   Paul| 24|         3| 20000|
| Harsha| 21|         1| 15000|
|Shubham| 23|         2| 18000|
+-------+---+----------+------+
</code></pre>
<p>​    </p>
<p>如果是字符串，用 and 表示同时满足多个条件<br>如果是用column，用( &amp; ) 连接多个条件</p>
<pre><code class="python">df_spark.filter(&quot;Salary &lt;= 20000 and age &lt;= 24&quot;).show()
</code></pre>
<pre><code>+-------+---+----------+------+
|   Name|age|Experience|Salary|
+-------+---+----------+------+
|   Paul| 24|         3| 20000|
| Harsha| 21|         1| 15000|
|Shubham| 23|         2| 18000|
+-------+---+----------+------+
</code></pre>
<p>​    </p>
<pre><code class="python">df_spark.filter(
    (df_spark[&quot;Salary&quot;]&lt;=20000)
    &amp; (df_spark[&quot;age&quot;]&lt;=24)
).show()
</code></pre>
<pre><code>+-------+---+----------+------+
|   Name|age|Experience|Salary|
+-------+---+----------+------+
|   Paul| 24|         3| 20000|
| Harsha| 21|         1| 15000|
|Shubham| 23|         2| 18000|
+-------+---+----------+------+
</code></pre>
<p>​    </p>
<pre><code class="python">column中，用|表示或， ~表示取反
</code></pre>
<pre><code class="python">df_spark.filter(
    (df_spark[&quot;Salary&quot;]&lt;=20000)
    | (df_spark[&quot;age&quot;]&lt;=24)
).show()
</code></pre>
<pre><code>+-------+---+----------+------+
|   Name|age|Experience|Salary|
+-------+---+----------+------+
|  Sunny| 29|         4| 20000|
|   Paul| 24|         3| 20000|
| Harsha| 21|         1| 15000|
|Shubham| 23|         2| 18000|
+-------+---+----------+------+
</code></pre>
<p>​    </p>
<pre><code class="python">df_spark.filter(
    (df_spark[&quot;Salary&quot;]&lt;=20000)
    | ~(df_spark[&quot;age&quot;]&lt;=24)
).show()
</code></pre>
<pre><code>+---------+---+----------+------+
|     Name|age|Experience|Salary|
+---------+---+----------+------+
|    Krish| 31|        10| 30000|
|Sudhanshu| 30|         8| 25000|
|    Sunny| 29|         4| 20000|
|     Paul| 24|         3| 20000|
|   Harsha| 21|         1| 15000|
|  Shubham| 23|         2| 18000|
+---------+---+----------+------+
</code></pre>
<p>​    </p>
<h3 id="分组聚合"><a href="#分组聚合" class="headerlink" title="分组聚合"></a>分组聚合</h3><p>换一个数据集test3</p>
<p><img src="https://s1.328888.xyz/2022/06/12/CS63i.png" alt="CS63i.png"></p>
<pre><code class="python">df_spark = spark.read.csv(&quot;./data/test3.csv&quot;, header=True, inferSchema=True)
df_spark.show()
</code></pre>
<pre><code>+---------+------------+------+
|     Name| Departments|salary|
+---------+------------+------+
|    Krish|Data Science| 10000|
|    Krish|         IOT|  5000|
|   Mahesh|    Big Data|  4000|
|    Krish|    Big Data|  4000|
|   Mahesh|Data Science|  3000|
|Sudhanshu|Data Science| 20000|
|Sudhanshu|         IOT| 10000|
|Sudhanshu|    Big Data|  5000|
|    Sunny|Data Science| 10000|
|    Sunny|    Big Data|  2000|
+---------+------------+------+
</code></pre>
<p>​    </p>
<p>使用groupby方法对dataframe某些列进行分组</p>
<pre><code class="python">df_spark.groupBy(&quot;Name&quot;)
</code></pre>
<pre><code>&lt;pyspark.sql.group.GroupedData at 0x227454d4be0&gt;
</code></pre>
<p>可以看到分组的结果是GroupedData对象，它不能使用show等方法打印<br>GroupedData对象需要进行聚合操作，才能重新转换为dataframe<br>聚合函数有sum、count、avg、max、min等</p>
<pre><code class="python">df_spark.groupBy(&quot;Departments&quot;).sum().show()
</code></pre>
<pre><code>+------------+-----------+
| Departments|sum(salary)|
+------------+-----------+
|         IOT|      15000|
|    Big Data|      15000|
|Data Science|      43000|
+------------+-----------+
</code></pre>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls"
                data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
            <ul id="audio-list" style="display:none">
                
                
                <li title='0' data-url='/statics/GrantEtude.mp3'></li>
                
                    
            </ul>
            
                        
            
            
    <div id='gitalk-container' class="comment link"
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d=''
        data-p='https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token'
    >Comments</div>


            
            
        </div>
        <div class="sidebar">
            <div class="box animated fadeInRight">
                <div class="subbox">
                    <img src="https://s1.328888.xyz/2022/06/04/W7Vg3.jpg" height=300 width=300></img>
                    <p>曾粤</p>
                    <span>I think,therefore I am</span>
                    <dl>
                        
                        
                            
                                <dd>
                                    <link rel="stylesheet" type="text/css" href="">
                                    <a href="function link() { [native code] }" target="_blank"><span
                                    class=" iconfont "></span></a>
                                </dd>
                            
                            
                            
                        
                    </dl>
                </div>
                <ul>
                    <li><a href="/">14 <p>Articles</p></a></li>
                    <li><a href="/categories">8 <p>Categories</p></a></li>
                    <li><a href="/tags">11 <p>Tags</p></a></li>
                </ul>
            </div>
            
            
            
            <div class="box sticky animated fadeInRight faster">
                <div id="toc" class="subbox">
                    <h4>Contents</h4>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#PySpark%E6%9E%81%E9%80%9F%E5%85%A5%E9%97%A8"><span class="toc-number">1.</span> <span class="toc-text">PySpark极速入门</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%EF%BC%9APyspark%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%89%E8%A3%85"><span class="toc-number">1.1.</span> <span class="toc-text">一：Pyspark简介与安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%EF%BC%9A%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5"><span class="toc-number">1.2.</span> <span class="toc-text">二：编程实践</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E3%80%81%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE"><span class="toc-number">1.2.1.</span> <span class="toc-text">加载、转换数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E7%BC%BA%E5%A4%B1%E5%80%BC"><span class="toc-number">1.2.2.</span> <span class="toc-text">处理缺失值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E6%BB%A4%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.3.</span> <span class="toc-text">过滤操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88"><span class="toc-number">1.2.4.</span> <span class="toc-text">分组聚合</span></a></li></ol></li></ol></li></ol>
                </div>
            </div>
            
            
        </div>
    </div>
</div>

    </div>
</div>
    <div id="back-to-top" class="animated fadeIn faster">
        <div class="flow"></div>
        <span class="percentage animated fadeIn faster">0%</span>
        <span class="iconfont icon-top02 animated fadeIn faster"></span>
    </div>
</body>
<footer>
    <p class="copyright" id="copyright">
        &copy; 2022
        <span class="gradient-text">
            Zeng Yue
        </span>.
        Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a>
        Theme
        <span class="gradient-text">
            <a href="https://github.com/TriDiamond/hexo-theme-obsidian" title="Obsidian" target="_blank" rel="noopener">Obsidian</a>
        </span>
        <small><a href="https://github.com/TriDiamond/hexo-theme-obsidian/blob/master/CHANGELOG.md" title="v1.4.9.3" target="_blank" rel="noopener">v1.4.9.3</a></small>
        
        
    </p>
</footer>

<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script>
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX", "TeX"],
      linebreaks: {
        automatic: true
      },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"]
      ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      noUndefined: {
        attributes: {
          mathcolor: "red",
          mathbackground: "#FFEEEE",
          mathsize: "90%"
        }
      },
      Macros: {
        href: "{}"
      }
    },
    messageStyle: "none"
  });
</script>
<script>
  function initialMathJax() {
    MathJax.Hub.Queue(function () {
      var all = MathJax.Hub.getAllJax(),
        i;
      // console.log(all);
      for (i = 0; i < all.length; i += 1) {
        console.log(all[i].SourceElement().parentNode)
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  }

  function reprocessMathJax() {
    if (typeof MathJax !== 'undefined') {
      MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
    }
  }
</script>


 
<link rel="stylesheet" href="//cdn.bootcss.com/gitalk/1.5.0/gitalk.min.css">
 
<script src="//cdn.bootcss.com/gitalk/1.5.0/gitalk.min.js"></script>
  
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/obsidian.js"></script>
<script src="/js/jquery.truncate.js"></script>
<script src="/js/search.js"></script>
 
<script src="//cdn.bootcss.com/typed.js/2.0.10/typed.min.js"></script>
 
<script src="//cdn.bootcss.com/blueimp-md5/2.12.0/js/md5.min.js"></script>
 
<script src="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>


<script src="https://cdn.bootcss.com/codemirror/5.48.4/codemirror.min.js"></script>
 
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/javascript/javascript.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/css/css.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/xml/xml.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/htmlmixed/htmlmixed.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/clike/clike.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/php/php.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/shell/shell.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/python/python.min.js"></script>
   
<script src="/js/busuanzi.min.js"></script>

<script>
  $(document).ready(function () {
    if ($('span[id^="busuanzi_"]').length) {
      initialBusuanzi();
    }
  });
</script>
 
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/default-skin/default-skin.min.css">


<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
  

<script>
  function initialTyped() {
    var typedTextEl = $('.typed-text');
    if (typedTextEl && typedTextEl.length > 0) {
      var typed = new Typed('.typed-text', {
        strings: ['勇俭爱诚', '厚德博学，唯实求新'],
        typeSpeed: 90,
        loop: true,
        loopCount: Infinity,
        backSpeed: 20,
      });
    }
  }

  if ($('.article-header') && $('.article-header').length) {
    $(document).ready(function () {
      initialTyped();
    });
  }
</script>




<!-- 引用依赖 -->
<script>document.write(aplayerconf)</script>




</html>
